{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lXZcnR0_A5K",
        "outputId": "7a6e31b6-7593-4e9b-887f-53352b515d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAPifeGE_I_E",
        "outputId": "a0dc05b6-4edf-459e-dded-05e12860abd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-nzs45y9k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-nzs45y9k\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=6af67f070b99de1c4d98f965d0164fa9c2ab010321c6a3bbf5f3819d05f8119d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xhs908i9/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyvbBh-9_KY6",
        "outputId": "8625daf8-fc82-43b7-cac3-1dda4cdf53c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#define m 10\n",
        "__global__ void mul_r(int *a, int *b, int *c)\n",
        "{\n",
        " \tint tid = threadIdx.x;\n",
        " \tif (tid < m)\n",
        "  {\n",
        " \t\tc[tid]= a[tid] * b[tid];\n",
        " \t}\n",
        "}\n",
        "int main()\n",
        "{\n",
        " \tint  n, c, d, fst[10][10], snd[10][10], t_snd[10][10];\n",
        " \tint row,col,sum_c, a[10], b[10], ans[10];\n",
        "  n=m;\n",
        "  for (c = 0; c < m; c++)\n",
        "  {\n",
        "    for (d = 0; d < n; d++)\n",
        " \t  {\n",
        " \t\t fst[c][d]=rand()%10+1;\n",
        " \t\t}\n",
        " \t}\n",
        " \tprintf(\"display the elements of first matrix\\n\");\t \n",
        " \tfor (c = 0; c < m; c++) \n",
        "  {\n",
        "    for (d = 0 ; d < n; d++) \n",
        "    {\n",
        " \t\t\tprintf(\"%d\\t\", fst[c][d]);\n",
        " \t\t}\n",
        " \t\tprintf(\"\\n\");\t \n",
        " \t}\n",
        "  for (c = 0; c < m; c++)\n",
        "  { \n",
        "    for (d = 0; d < n; d++)\n",
        " \t  {\n",
        " \t\t snd[c][d]=rand()%10+1;\n",
        " \t\t}\n",
        " \t}\n",
        " \tprintf(\"display the elements of second matrix\\n\");\t \n",
        " \tfor (c = 0; c < m; c++) \n",
        "  {\n",
        "    for (d = 0 ; d < n; d++) \n",
        "    {\n",
        " \t\t\tprintf(\"%d\\t\", snd[c][d]);\n",
        " \t\t}\n",
        " \t\tprintf(\"\\n\");\t \n",
        " \t}\n",
        " \tfor(c=0; c<m; c++)\n",
        "  for(d=0; d<n; d++)\n",
        "  {\n",
        "    t_snd[d][c] = snd[c][d];\n",
        "  }\n",
        "  printf(\"\\nTranspose of second Matrix:\\n\");\n",
        "  for (c = 0; c < n; c++) \n",
        "  {\n",
        "    for (d = 0 ; d < m; d++) \n",
        "    {\n",
        " \t\t\tprintf(\"%d\\t\", t_snd[c][d]);\n",
        " \t\t}\n",
        " \t\tprintf(\"\\n\");\t \n",
        " \t}\n",
        " \tint *dev_a, *dev_b,*dev_ans;\n",
        " \tcudaError_t err=cudaSuccess;\n",
        " \terr=cudaMalloc((void**)&dev_a,m * sizeof(int)); \n",
        " \tif (err !=cudaSuccess)\n",
        " \t{ \t\n",
        "  printf(\"failed to  allocate on device \\n\");\n",
        " \tprintf(\"error is:\\n\",cudaGetErrorString(err));\n",
        " \texit(EXIT_FAILURE);\n",
        " \t}\n",
        " \tcudaMalloc((void**)&dev_b,m * sizeof(int)); \n",
        " \tcudaMalloc((void**)&dev_ans,m * sizeof(int)); \n",
        " \trow=0;\n",
        " \tcol=0;\n",
        "  cudaEvent_t start, end;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&end);\n",
        "  cudaEventRecord(start);\t  \n",
        " \tfor(row=0; row<m; row++)\n",
        "  {\t\n",
        " \t for (d = 0 ; d < m; d++) \n",
        "   {\n",
        " \t\ta[d]=fst[row][d];\n",
        " \t }\n",
        " \t cudaMemcpy(dev_a,a,m*sizeof(int), cudaMemcpyHostToDevice);\t\n",
        " \t for (col=0; col<m; col++)\n",
        "   {\t\n",
        " \t  for (d= 0 ; d < m; d++) \n",
        "    {\n",
        " \t\t\tb[d]=t_snd[col][d];\n",
        " \t\t\tans[d]=0;\n",
        " \t\t}\n",
        " \t\tcudaMemcpy(dev_b,b,m*sizeof(int), cudaMemcpyHostToDevice);\t\n",
        " \t\tcudaMemcpy(dev_ans,ans,m*sizeof(int), cudaMemcpyHostToDevice);\n",
        " \t\tmul_r<<<1,m>>>(dev_a,dev_b,dev_ans);\n",
        " \t\terr=cudaMemcpy(ans,dev_ans,m*sizeof(int), cudaMemcpyDeviceToHost);\n",
        " \t\tif (err !=cudaSuccess)\n",
        " \t\t{ \t\n",
        "        printf(\"failed to  copy from device \\n\");\n",
        " \t\t\t\texit(EXIT_FAILURE);\n",
        " \t\t}\n",
        " \t  sum_c=0;\n",
        " \t  for (d = 0 ; d < m; d++) \n",
        "    {\n",
        " \t\t\t\tsum_c+=ans[d];\n",
        " \t\t}\n",
        " \t  snd[row][col]=sum_c; \n",
        " \t }\n",
        "  }\n",
        " \tcudaEventRecord(end);\n",
        "  cudaEventSynchronize(end);\n",
        "  float time = 0;\n",
        "  cudaEventElapsedTime(&time, start, end);\n",
        "  printf(\"execution time=%f\\n\",time);\n",
        " \tprintf(\" Matrix multipliation ans=:\\n\");\n",
        "  for (c = 0; c < n; c++) \n",
        "  {\n",
        "    for (d = 0 ; d < m; d++) \n",
        "    {\n",
        " \t\t\tprintf(\"%d\\t\", snd[c][d]);\n",
        " \t\t}\n",
        " \t\tprintf(\"\\n\");\t \n",
        " \t}\n",
        " \treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njw-am4o_MA4",
        "outputId": "fbf0cdd6-c4f1-4eee-eb6b-3076d4fb1442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display the elements of first matrix\n",
            "4\t7\t8\t6\t4\t6\t7\t3\t10\t2\t\n",
            "3\t8\t1\t10\t4\t7\t1\t7\t3\t7\t\n",
            "2\t9\t8\t10\t3\t1\t3\t4\t8\t6\t\n",
            "10\t3\t3\t9\t10\t8\t4\t7\t2\t3\t\n",
            "10\t4\t2\t10\t5\t8\t9\t5\t6\t1\t\n",
            "4\t7\t2\t1\t7\t4\t3\t1\t7\t2\t\n",
            "6\t6\t5\t8\t7\t6\t7\t10\t4\t8\t\n",
            "5\t6\t3\t6\t5\t8\t5\t5\t4\t1\t\n",
            "8\t9\t7\t9\t9\t5\t4\t2\t5\t10\t\n",
            "3\t1\t7\t9\t10\t3\t7\t7\t5\t10\t\n",
            "display the elements of second matrix\n",
            "6\t1\t5\t9\t8\t2\t8\t3\t8\t3\t\n",
            "3\t7\t2\t1\t7\t2\t6\t10\t5\t10\t\n",
            "1\t10\t2\t8\t8\t2\t2\t6\t10\t8\t\n",
            "8\t7\t8\t4\t7\t6\t7\t4\t10\t5\t\n",
            "9\t2\t3\t10\t4\t10\t1\t9\t9\t6\t\n",
            "1\t10\t7\t4\t9\t6\t7\t2\t2\t6\t\n",
            "10\t9\t5\t9\t2\t1\t4\t1\t5\t5\t\n",
            "5\t5\t8\t7\t4\t2\t8\t6\t10\t7\t\n",
            "3\t2\t8\t9\t6\t8\t5\t2\t9\t6\t\n",
            "10\t8\t6\t4\t9\t9\t4\t2\t9\t10\t\n",
            "\n",
            "Transpose of second Matrix:\n",
            "6\t3\t1\t8\t9\t1\t10\t5\t3\t10\t\n",
            "1\t7\t10\t7\t2\t10\t9\t5\t2\t8\t\n",
            "5\t2\t2\t8\t3\t7\t5\t8\t8\t6\t\n",
            "9\t1\t8\t4\t10\t4\t9\t7\t9\t4\t\n",
            "8\t7\t8\t7\t4\t9\t2\t4\t6\t9\t\n",
            "2\t2\t2\t6\t10\t6\t1\t2\t8\t9\t\n",
            "8\t6\t2\t7\t1\t7\t4\t8\t5\t4\t\n",
            "3\t10\t6\t4\t9\t2\t1\t6\t2\t2\t\n",
            "8\t5\t10\t10\t9\t2\t5\t10\t9\t9\t\n",
            "3\t10\t8\t5\t6\t6\t5\t7\t6\t10\t\n",
            "execution time=3.663232\n",
            " Matrix multipliation ans=:\n",
            "278\t357\t303\t377\t361\t261\t288\t251\t428\t372\t\n",
            "290\t323\t301\t264\t348\t268\t300\t248\t389\t355\t\n",
            "289\t342\t287\t316\t358\t263\t274\t268\t451\t385\t\n",
            "353\t323\t330\t400\t375\t295\t327\t276\t456\t348\t\n",
            "350\t344\t352\t406\t369\t266\t349\t236\t439\t340\t\n",
            "198\t196\t186\t254\t238\t205\t183\t196\t274\t253\t\n",
            "404\t413\t374\t427\t418\t319\t359\t306\t526\t445\t\n",
            "249\t295\t265\t301\t303\t218\t269\t223\t341\t301\t\n",
            "405\t408\t342\t418\t463\t360\t336\t329\t535\t463\t\n",
            "413\t381\t345\t429\t379\t345\t287\t272\t525\t412\t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rD7xvIoV_N6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}